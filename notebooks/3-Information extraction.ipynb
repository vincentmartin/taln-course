{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3. - Extraction d'informations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons mettre en oeuvre des techniques d'extraction d'informations.\n",
    "\n",
    "A partir du texte extrait des documents, l'objectif est d'extraire des informations métiers intéressantes comme des références, des noms de personnes, des lieux géographiques etc. \n",
    "\n",
    "L'extraction d'informations peut être très utile lorsque l'on cherche à _structurer_ des données qui ne le sont pas de base, comme du texte brut. Les cas d'usage les plus fréquents sont :\n",
    "- trouver et comprendre des portions de textes pertinentes pour la réalisation d'une tâche;\n",
    "- calculer des statistiques sur les objets les plus fréquents, par exemple les personnes les plus cités dans des articles;\n",
    "- trouver des liens entre des objets, par exemple les liens entre des sociétés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des bibliothèques logicielles et configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Requirement already satisfied: fr-core-news-md==3.3.0 from https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.3.0/fr_core_news_md-3.3.0-py3-none-any.whl#egg=fr_core_news_md==3.3.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (3.3.0)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from fr-core-news-md==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: setuptools in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (47.1.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (2.28.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\" in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (4.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (1.21.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (3.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (2.0.12)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-md==3.3.0) (4.11.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/vincent/dev/FORMATION_DATA_SCIENCES/taln-course/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "import re # mise en oeuvre d'expression régulières\n",
    "import ast # à ignorer pour ce TP\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extraction d'informations par expressions régulières"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une **expression régulière** est chaîne de caractères décrivant un ensemble de chaînes de caractères possibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, chargement le jeu de données créé en Partie 1. Nous travaillerons sur un sous ensemble de ce jeu de données pour garantir des temps de réponse acceptables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset_processed/dataset.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27257/2490233261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./dataset_processed/dataset.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdocuments_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbig_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset_processed/dataset.json'"
     ]
    }
   ],
   "source": [
    "f = open(\"./dataset_processed/dataset.json\", \"r\")\n",
    "documents_raw = f.read()\n",
    "documents = ast.literal_eval(documents_raw)\n",
    "f.close()\n",
    "big_text = ' '.join([doc['content'] for doc in documents.values()])\n",
    "big_text = big_text[0:1000000] # sélection d'un sous ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des lois et décrets\n",
    "\n",
    "Les lois et décrets ont un numéro codifié. Ce dernier se compose de l'année sur 2 ou 4 chiffres, suivi d'un tiret (-), suivi d'un numéro sur au moins 2 chiffres. Par exemple : \n",
    "- loi n° 2013-595\n",
    "- décret n° 2011-1503"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : écrire l'expression régulière permettant d'extraire l'ensemble des numéros des lois et des décrets cités dans le jeu de données. Pour simplifier l'exercice, n'extraire que les numéros sans le texte `décret n°` ou `loi n°`. Afficher le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'big_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27257/2690018725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl_regex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\" [0-9]{2}-|[0-9]{4}-[0-9]{2,5} \"\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_regex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'big_text' is not defined"
     ]
    }
   ],
   "source": [
    "url_regex = r\"\" # TODO\n",
    "match = set(re.findall(url_regex, big_text, re.IGNORECASE))\n",
    "print(match)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des mails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un autre exemple est celui de l'extraction des adresses email dans des textes. Une adresse email se décomposer de la manière suivante : `texte@nom_hote.domaine`.\n",
    "\n",
    "**Exercice** : écrire l'exression régulière permettant d'extraire l'ensemble des adresses email citées dans le jeu de données. Afficher le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_regex = \"\" # TODO expression régulière permettant de cibler un mail.\n",
    "match = re.findall(mail_regex, big_text)\n",
    "for i in match:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction d'URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'extraction d'URL par expression régulière n'est si triviale qu'elle n'y paraît. Aujourd'hui, les navigateurs acceptent des URLs même si elles ne sont pas parfaitement formées. Par exemple, il n'est pas obligatoire de spécifier `https` ou `www`. \n",
    "\n",
    "Voici ci-dessous un exemple d'expression régulière permettant d'extraire les URLs, et elle n'est pas simple à comprendre. Essayons là en lançant le bloc de codes ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "match = set(re.findall(url_regex, big_text))\n",
    "for i in match:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extraction d'informations via un modèle entraîné."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les expressions régulières sont un puissant outil pour extraire de l'information structurée mais uniquement lorsque l'on est capable de décrire précisément et sans ambiguïté ce que l'on cherche.\n",
    "\n",
    "Dans certains cas, cela est impossible ou très difficile. Par exemple lorsque l'on veut extraire des noms de personnes, des lieux géographiques ou encore des noms de société. Dans ces cas là, nous ne pouvons plus utiliser les expressions régulières car la variabilité des cas possibles est trop grande.\n",
    "\n",
    "Pour répondre à ce problème, nous pouvons utiliser des modèles statistiques ayant préalablement été entraînés à identifier dans un texte les séquences de mots reflétant ce que l'on souhaite extraire.\n",
    "\n",
    "Un exemple bien connu de ce type d'extraction est la **Reconnaissance d'Entités Nommées** (_Named Entity Recognition_). Une entité nommée est un mot ou une séquence de mots catégorisable dans des classes. Les classes les plus connues sont : `Personne`, `Organisation`, `Lieu géographique`, `Montant`, `Quantité`, `Date`, `Distance`.\n",
    "\n",
    "Dans le code ci-dessous, nous allons mettre en oeuvre l'extraction d'entités nommées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premièrement, chargeons avec la bibliothèque `spacy` un modèle ayant préalablement été entraîné à reconnaître les entités nommées dans des textes en langue française."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md') # Chargement d'un modèle de TALN pour le français."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d'exploiter le jeu de données créé précédemment, nous allons travailler sur le texte de taille réduite ci-dessous (extrait de Wikipedia) afin de mieux visualiser les extractions, leurs forces et leurs limites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "La société Naval Group est un groupe industriel français spécialisé dans la construction navale de défense. \n",
    "Le groupe emploie 15 792 personnes en 2020 à travers dix-huit pays. \n",
    "Société de droit privé détenue principalement à hauteur de 62,49 % par l’État français et de 35 % par Thales, \n",
    "Naval Group est, depuis 2017, l’héritière des arsenaux français et de la Direction des constructions et armes navales (DCAN), \n",
    "devenue la Direction des constructions navales (DCN) en 1991 et DCNS en 2007 (le « s » ajouté pour la notion de système et de service). \n",
    "Depuis 2021, le groupe se recentre sur ses activités navales. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lançons maintenant l'analyse du texte. La ligne `nlp(text)` réalise de nombreuses opérations comme la _tokenisation_ et la normalisation du texte en plus de l'extraction des entités nommées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "# Affichage des entités nommées.\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi afficher les résultats de manière plus visuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats permettent d'identifier des informations itnéressantes, comme des organisations, que celles-ci soient écrites sous la forme d'un acronyme ou pas. Le modèle n'est néanmoins pas parfait et des erreurs peuvent survenir. _Thales_ est par exemple reconnu comme une localisation géographique. _Naval Group_ à la troisième ligne n'est pas reconnu comme une organisation.\n",
    "\n",
    "Ces résultats pourraient être améliorés en utilisant un modèle plus conséquent. Pour la bibliothèque _Spacy_ que nous utilisons, la liste des modèles pour la langue française est disponible ici https://spacy.io/models/fr#fr_dep_news_trf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous avons enfin commencé à extraire des informations pertinentes. L'extraction d'informations à partir d'un modèle pré-entraîné s'appuie sur les techniques vues précédemment pour normaliser le texte avant son analyse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "051e87607299e8fe007fcacfd48fd3303246d4e5a4af1840d943aebbb601e356"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
