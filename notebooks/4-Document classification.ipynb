{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 4. - Classification documentaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classification documentaire consiste à catégoriser un texte ou un document dans une ou plusieurs catégorie prédéfinie. \n",
    "\n",
    "Les principes généraux sont les mêmes que ceux vus pour la classification d'images, à la différence que les données d'entrée ne sont pas des images mais du texte.\n",
    "\n",
    "Il existe de nombreux algorithmes de classification de documents. Cependant, ceux qui fonctionnent le mieux à ce jour sont les systèmes reposant sur une représentation vectorielle des documents car celle-ci _encode_ le sens des informations et évite les écueils liés aux grandes variabilités syntaxiques que l'on retrouve dans les textes.\n",
    "\n",
    "Pour cette partie, nous allons utiliser un modèle pré-entraîné de type BERT. \n",
    "\n",
    "Nouveauté par rapport au cours, nous allons étudier un modèle de classification _zero shot_ qui permet de spécifier les étiquettes lors de la phase d'inférence et non plus à l'entraînement. Ce nouveau type de modèle facilite grandement la mise en place d'un nouveau classifieur. La contre partie est des performances moindre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des bibliothèques logicielles et configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification # Tokenizer & classification de textes à partir de transformers.\n",
    "from transformers import pipeline # Mise en oeuvre de chaînes de traitement.\n",
    "from datasets import load_dataset # Intégration de jeux de données.\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PRE_TRAINED_MODEL_NAME = \"BaptisteDoyen/camembert-base-xnli\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement du jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le cas d'usage que nous allons résoudre est la classification de d'opinions d'avis utilisateur sur des livres.\n",
    "\n",
    "Pour ce TP, l'opinion est binaire : **positif** ou **négatif**.\n",
    "\n",
    "Première étape : récupération du jeu de données. Pour cela, exécuter la commande suivante qui permettre de télécharger les données depuis Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_book_review_dataset = load_dataset(\"Abirate/french_book_reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement du modèle pré-entraîné et configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, chargeons un modèle pré-entraîné à la classification _zero shot_. Le modèle que nous utilisons est un modèle ayant été appris sur la partie française du jeu de donées _XNLI_ (https://github.com/facebookresearch/XNLI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading or downloading model {}\".format(PRE_TRAINED_MODEL_NAME))\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME) # Chargement du tokenizer.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME) # Chargement du modèle pour la classification de séquences de textes.\n",
    "classifier = pipeline(\"zero-shot-classification\", model=PRE_TRAINED_MODEL_NAME) # Réalisation de la chaîne de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le modèle est chargé, spécifions les catégories (_labels_) dans lesquels nous allons classer nos documents : **positif**, **négatif**.\n",
    "\n",
    "Nous spécifions aussi une hypothèse pour mieux catégoriser le document. L'idée est d'estimer la probabilité conditionnelle `P(label|hypothèse)` pour chaque texte puis de sélectionner le label qui maximise cette probabilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"négatif\", \"positif\"] # catégories.\n",
    "hypothesis_template = \"L'avis sur ce livre est plutôt {}.\" # Hypothèse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage du format du dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(french_book_review_dataset.data[\"train\"])\n",
    "print(french_book_review_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'être traité efficacement, le texte est transformé en vecteurs pour encoder le sens des informations. Ces vecteurs sont appelés des **embeddings**.\n",
    "\n",
    "Ci-dessous, nous visualisons un de ces vecteurs. Il n'est pas compréhensible directement par un humain mais il l'est par la machine qui peut l'exploiter pour réaliser différentes tâches !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_vector = pipeline('feature-extraction', model=PRE_TRAINED_MODEL_NAME)\n",
    "embedding = pipeline_vector(\"Ceci est un texte d'exemple !\")\n",
    "print(\"Embedding du mot 'Ceci':\")\n",
    "print(\"\")\n",
    "print(embedding[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation du classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer notre classifieur, nous allons utiliser la métrique simple de la précision : `nombre de bonnes prédictions / # total de prédictions`.\n",
    "\n",
    "Il est aussi possible d'utiliser d'autres métriques comme le score `F1` ou d'autres que vous avez vu aux TPs précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(dataset, model):\n",
    "    \"\"\"\n",
    "    Fonction prenant en paramètre le jeu de données et un modèle et retournant la précision des prédictions.\n",
    "    \"\"\"\n",
    "    predictions, groudtruth = [], []\n",
    "    correct_classification_count = 0\n",
    "    accuracy = 0.0\n",
    "    for text, label in tqdm(zip(dataset.data[\"train\"][\"reader_review\"], dataset.data[\"train\"][\"label\"]), total=len(dataset.data[\"train\"])):\n",
    "        if(text.as_py() is None or text.as_py() == \"\"):\n",
    "            continue\n",
    "        \n",
    "        prediction = model(text.as_py(), labels, multi_label=False, hypothesis_template=hypothesis_template)\n",
    "        predicted_label = prediction[\"labels\"][0]\n",
    "        predicted_label_int = 1 if predicted_label == \"positif\" else 0\n",
    "        predictions.append(predicted_label)\n",
    "        groudtruth.append(label)\n",
    "        if (predicted_label_int == label.as_py()):\n",
    "            correct_classification_count += 1\n",
    "        accuracy = correct_classification_count / len(predictions)\n",
    "        if(len(predictions) % 100 == 0):\n",
    "            print(\"Accuracy after {} texts processed = {}\".format(len(predictions), accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lançons la classification sur l'ensemble des documents. Toutes les 100 prédictions, la fonction `evaluate_classifier` retourne la précision. \n",
    "\n",
    "Si le temps de traitement est trop long, vous pouvez arrêter le processus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = evaluate_classifier(french_book_review_dataset, classifier)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont encourageants, d'autant qu'aucune phase d'apprentissage n'a été réalisé préalablement.\n",
    "\n",
    "L'avantage de cette approche est qu'elle permet de définir beaucoup plus rapidement de nouvelles chaînes de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test sur des textes écrits par vous !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécute le bloc de code ci-dessous pour saisir un texte. Le programme vous indiquera si ce qui est écrit est positif ou négatif !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_widget = widgets.Text( description='Votre avis?' )\n",
    "output_widget = widgets.Label(value='En attente...' )\n",
    "\n",
    "vb=widgets.VBox([user_input_widget, output_widget])\n",
    "\n",
    "\n",
    "def callback(wdgt):\n",
    "    prediction = classifier(user_input_widget.value, labels, multi_label=False, hypothesis_template=hypothesis_template)\n",
    "    predicted_label = prediction[\"labels\"][0]\n",
    "    score = prediction[\"scores\"][0]\n",
    "    output_widget.value=\"{} avec un score de {}\".format(predicted_label, score)\n",
    "\n",
    "\n",
    "user_input_widget.on_submit(callback)\n",
    "\n",
    "display(vb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Création d'un nouveau classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : modifier le code ci-dessous pour classer les documents selons les catégories suivantes : `subjectif`, `objectif`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_category_label = [\"objectif\", \"subjectif\"] # TODO\n",
    "book_category_hypothesis_template = \"L'avis sur ce livre est {}.\" # TODO\n",
    "\n",
    "user_input_widget = widgets.Text( description='Votre avis?' )\n",
    "output_widget = widgets.Label(value='En attente...' )\n",
    "\n",
    "vb=widgets.VBox([user_input_widget, output_widget])\n",
    "\n",
    "\n",
    "def callback(wdgt):\n",
    "    prediction = classifier(user_input_widget.value, book_category_label, multi_label=False, hypothesis_template=book_category_hypothesis_template)\n",
    "    predicted_label = prediction[\"labels\"][0]\n",
    "    score = prediction[\"scores\"][0]\n",
    "    output_widget.value=\"{} avec un score de {}\".format(predicted_label, score)\n",
    "\n",
    "\n",
    "user_input_widget.on_submit(callback)\n",
    "\n",
    "display(vb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous avons vu la classification de documents. Point intéressant grâce aux récentes avancées scientifiques du domaine : il est possible de fournir les étiquettes à l'inférence !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c80391f1238b45698e2dd8cb3d47fccae97762fdc20421908c45a9aed68776a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
